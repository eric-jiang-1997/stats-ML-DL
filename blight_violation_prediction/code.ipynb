{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic - Predicting Property Maintenance Fines using ML models  \n",
    "\n",
    "___\n",
    "\n",
    "This is the final project of the Coursera course \"Applied Machine Learning in Python\" offered by University of Michigan. Some modifications have been made to provide a better presentation and a more complete process.\n",
    "\n",
    "This project is based on a data challenge from the Michigan Data Science Team ([MDST](http://midas.umich.edu/mdst/)). \n",
    "\n",
    "The Michigan Data Science Team ([MDST](http://midas.umich.edu/mdst/)) and the Michigan Student Symposium for Interdisciplinary Statistical Sciences ([MSSISS](https://sites.lsa.umich.edu/mssiss/)) have partnered with the City of Detroit to help solve one of the most pressing problems facing Detroit - blight. [Blight violations](http://www.detroitmi.gov/How-Do-I/Report/Blight-Complaint-FAQs) are issued by the city to individuals who allow their properties to remain in a deteriorated condition. Every year, the city of Detroit issues millions of dollars in fines to residents and every year, many of these fines remain unpaid. Enforcing unpaid blight fines is a costly and tedious process, so the city wants to know: how can we increase blight ticket compliance?\n",
    "\n",
    "The first step in answering this question is understanding when and why a resident might fail to comply with a blight ticket. This is where predictive modeling comes in. For this project, the task is to predict whether a given blight ticket will be paid on time.\n",
    "\n",
    "___\n",
    "\n",
    "\n",
    "**File descriptions**\n",
    "\n",
    "    train.csv - the training set (all tickets issued 2004-2011)\n",
    "    addresses.csv & latlons.csv - mapping from ticket id to addresses, and from addresses to lat/lon coordinates.  \n",
    "    (Note: I did not include 'test.csv' here, since the test file does not have any ground-truth target values, which means the evaluation is limited. Instead, I used the 'train.csv' to split the data into training set and test set, and then moved forward to later steps.)\n",
    "    \n",
    "\n",
    "___\n",
    "\n",
    "**Evaluation and Model Selection**\n",
    "\n",
    "The model is to predict whether the corresponding blight ticket will be paid on time.  \n",
    "  \n",
    "The performance metrics (accuracy, precision, recall, auc) are given to compare different models.       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test():\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    \n",
    "    data = pd.read_csv('readonly/train.csv',encoding='ISO-8859-1',low_memory=False)\n",
    "    # only include observations with target values 0 or 1\n",
    "    data = data[(data['compliance']==0) | (data['compliance']==1)]\n",
    "    address =  pd.read_csv('readonly/addresses.csv',encoding='ISO-8859-1',low_memory=False)\n",
    "    latlons = pd.read_csv('readonly/latlons.csv',encoding='ISO-8859-1',low_memory=False)\n",
    "    address_latlons = address.set_index('address').join(latlons.set_index('address'),how='left')\n",
    "    # combine to get the whole dataset\n",
    "    data_new = data.set_index('ticket_id').join(address_latlons.set_index('ticket_id'),how='left').reset_index()\n",
    "\n",
    "    # delete columns that are correlated with target value to avoid data leakage\n",
    "    train_columns_to_drop = ['payment_amount','payment_date','payment_status',\\\n",
    "                         'balance_due','collection_status','compliance_detail']\n",
    "    data_new.drop(train_columns_to_drop,axis=1,inplace=True)\n",
    "    # delete string variables\n",
    "    string_columns_to_drop = ['agency_name','inspector_name','violator_name',\\\n",
    "                     'violation_street_number','violation_street_name','violation_zip_code',\\\n",
    "                     'mailing_address_str_number', 'mailing_address_str_name', \\\n",
    "                     'city', 'state', 'zip_code', 'non_us_str_code', 'country',\\\n",
    "                     'ticket_issued_date','hearing_date','violation_code','violation_description',\\\n",
    "                     'disposition','grafitti_status']\n",
    "    data_new.drop(string_columns_to_drop,axis=1,inplace=True)\n",
    "\n",
    "    #check and deal with missing values\n",
    "    data_new.isnull().sum()\n",
    "    data_new.lat.fillna(method='pad',inplace=True)\n",
    "    data_new.lon.fillna(method='pad',inplace=True)\n",
    "\n",
    "    # split_train_test\n",
    "    X = data_new.drop('compliance',axis=1)\n",
    "    y = data_new['compliance']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9276457343007255"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Baseline: Dummy Classifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "X_train, X_test, y_train, y_test = split_train_test()\n",
    "# Negative class (0) is most frequent\n",
    "dummy_majority = DummyClassifier(strategy='most_frequent').fit(X_train, y_train)\n",
    "dummy_majority.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.93\n",
      "Precision: 0.76\n",
      "Recall: 0.06\n",
      "AUC: 0.53\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_curve, auc\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "X_train, X_test, y_train, y_test = split_train_test()\n",
    "logit = LogisticRegression(C=100).fit(X_train, y_train)\n",
    "logit_predicted = logit.predict(X_test)\n",
    "print('Accuracy: {:.2f}'.format(accuracy_score(y_test, logit_predicted)))\n",
    "print('Precision: {:.2f}'.format(precision_score(y_test, logit_predicted)))\n",
    "print('Recall: {:.2f}'.format(recall_score(y_test, logit_predicted)))\n",
    "fpr_logit, tpr_logit, _ = roc_curve(y_test, logit_predicted)\n",
    "roc_auc_logit = auc(fpr_logit, tpr_logit)\n",
    "print('AUC: {:.2f}'.format(roc_auc_logit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.93\n",
      "Precision: 0.43\n",
      "Recall: 0.08\n",
      "AUC: 0.53\n"
     ]
    }
   ],
   "source": [
    "# kNN Classification\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_curve, auc\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "X_train, X_test, y_train, y_test = split_train_test()\n",
    "knn = KNeighborsClassifier(n_neighbors=5).fit(X_train, y_train)\n",
    "knn_predicted = knn.predict(X_test)\n",
    "print('Accuracy: {:.2f}'.format(accuracy_score(y_test, knn_predicted)))\n",
    "print('Precision: {:.2f}'.format(precision_score(y_test, knn_predicted)))\n",
    "print('Recall: {:.2f}'.format(recall_score(y_test, knn_predicted)))\n",
    "fpr_knn, tpr_knn, _ = roc_curve(y_test, knn_predicted)\n",
    "roc_auc_knn = auc(fpr_knn, tpr_knn)\n",
    "print('AUC: {:.2f}'.format(roc_auc_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.93\n",
      "Precision: 0.95\n",
      "Recall: 0.09\n",
      "AUC: 0.54\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosted Decision Trees\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_curve, auc\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "X_train, X_test, y_train, y_test = split_train_test()\n",
    "tree = GradientBoostingClassifier(learning_rate=0.01,max_depth=2,random_state=0).fit(X_train, y_train)\n",
    "tree_predicted = tree.predict(X_test)\n",
    "print('Accuracy: {:.2f}'.format(accuracy_score(y_test, tree_predicted)))\n",
    "print('Precision: {:.2f}'.format(precision_score(y_test, tree_predicted)))\n",
    "print('Recall: {:.2f}'.format(recall_score(y_test, tree_predicted)))\n",
    "fpr_tree, tpr_tree, _ = roc_curve(y_test, tree_predicted)\n",
    "roc_auc_tree = auc(fpr_tree, tpr_tree)\n",
    "print('AUC: {:.2f}'.format(roc_auc_tree))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Conclusions\n",
    "\n",
    "___\n",
    "\n",
    "a) The overall accuracy and AUC score of the above 3 models are similar;  \n",
    "b) The baseline accuracy is 0.9276, which is very close to the 3 training models. This indicates that **there might be missing features, as training the model does not improve the accuracy a lot**;   \n",
    "c) Precision and Recall scores are various in these 3 models. Usually, there is a tradeoff between precision and recall. **For this case, we would like to decrease the number of false positives (False positive means we wrongly classify someone into compliance, but actually he does not pay in time. This will lead to the failure of collecting money back and negatively affect the financial situation of relevant parties.)** So it is better to use a model with **higher precision score**. Based on the above, we can safely conclude that the **Gradient Boosted Decision Trees with learning_rate 0.01 and max_depth 2** is a best model to predict blight violations."
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "python-machine-learning",
   "graded_item_id": "nNS8l",
   "launcher_item_id": "yWWk7",
   "part_id": "w8BSS"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
